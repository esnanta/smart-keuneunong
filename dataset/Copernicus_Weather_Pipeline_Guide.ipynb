{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e03a7ab",
   "metadata": {},
   "source": [
    "# Panduan Lengkap: Pipeline Data Cuaca (Copernicus ke Android MVVM)\n",
    "\n",
    "Panduan ini akan memandu Anda melalui seluruh proses end-to-end, dimulai dari mendapatkan kredensial API Copernicus, mengunduh dan memproses data 10 tahun di Google Colab, hingga mengintegrasikan database final ke dalam aplikasi Android modern yang menggunakan Jetpack Compose dan arsitektur MVVM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c960421f",
   "metadata": {},
   "source": [
    "## Fase 1: Konfigurasi Lingkungan Google Colab\n",
    "\n",
    "Langkah pertama adalah menyiapkan Google Colab untuk berkomunikasi dengan server Copernicus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54008c",
   "metadata": {},
   "source": [
    "### Langkah 1.1: Dapatkan Kredensial API Copernicus Anda\n",
    "\n",
    "Setelah Anda login ke portal Copernicus Climate Data Store (CDS):\n",
    "- Klik nama Anda di pojok kanan atas.\n",
    "- Navigasi ke halaman profil Anda.\n",
    "- Temukan bagian \"API key\".\n",
    "- Anda akan melihat sebuah kotak yang menampilkan url dan key Anda. Salin nilai key (ini adalah satu token akses personal yang panjang).\n",
    "- Biarkan halaman ini tetap terbuka. Anda akan segera menempelkan nilai ini."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb96e4d",
   "metadata": {},
   "source": [
    "### Langkah 1.2: Instal Pustaka cdsapi di Colab\n",
    "\n",
    "Di sel (cell) baru Google Colab, jalankan perintah berikut untuk menginstal dan meningkatkan (upgrade) pustaka Python ke versi terbaru, seperti yang disarankan oleh pesan error Anda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d3bdf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cdsapi==0.7.7\n",
      "  Downloading cdsapi-0.7.7-py2.py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: xarray in /usr/local/lib/python3.12/dist-packages (2025.11.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
      "Collecting ecmwf-datastores-client>=0.4.0 (from cdsapi==0.7.7)\n",
      "  Downloading ecmwf_datastores_client-0.4.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: requests>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from cdsapi==0.7.7) (2.32.4)\n",
      "Requirement already satisfied: numpy>=1.26 in /usr/local/lib/python3.12/dist-packages (from xarray) (2.0.2)\n",
      "Requirement already satisfied: packaging>=24.1 in /usr/local/lib/python3.12/dist-packages (from xarray) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi==0.7.7) (25.4.0)\n",
      "Collecting multiurl>=0.3.7 (from ecmwf-datastores-client>=0.4.0->cdsapi==0.7.7)\n",
      "  Downloading multiurl-0.3.7-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from ecmwf-datastores-client>=0.4.0->cdsapi==0.7.7) (4.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi==0.7.7) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi==0.7.7) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi==0.7.7) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.5.0->cdsapi==0.7.7) (2025.11.12)\n",
      "Downloading cdsapi-0.7.7-py2.py3-none-any.whl (12 kB)\n",
      "Downloading ecmwf_datastores_client-0.4.1-py3-none-any.whl (29 kB)\n",
      "Downloading multiurl-0.3.7-py3-none-any.whl (21 kB)\n",
      "Installing collected packages: multiurl, ecmwf-datastores-client, cdsapi\n",
      "Successfully installed cdsapi-0.7.7 ecmwf-datastores-client-0.4.1 multiurl-0.3.7\n"
     ]
    }
   ],
   "source": [
    "!pip install cdsapi==0.7.7 xarray pandas tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea39ad8",
   "metadata": {},
   "source": [
    "### Langkah 1.3: Konfigurasikan Kredensial API Anda di Colab\n",
    "\n",
    "Jalankan kode Python berikut di sel Colab baru. Ganti 'GANTI_DENGAN_TOKEN_ANDA_DARI_WEBSITE' dengan nilai key (Personal Access Token) Anda. Perhatikan bahwa url telah diperbaiki (tanpa /v2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a07e135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File .cdsapirc berhasil dibuat/diperbarui!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# GANTI DENGAN KREDENSIAL ANDA\n",
    "YOUR_API_TOKEN = \"25171a66-2fb9-4d0e-95ff-ecfd24c9d6d4\" \n",
    "\n",
    "# Kode ini akan membuat file konfigurasi .cdsapirc di lingkungan Colab\n",
    "# URL telah diperbaiki ke 'https://cds.climate.copernicus.eu/api'\n",
    "api_key_content = f\"\"\"\n",
    "url: https://cds.climate.copernicus.eu/api\n",
    "key: {YOUR_API_TOKEN}\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{os.path.expanduser('~')}/.cdsapirc\", \"w\") as f:\n",
    "    f.write(api_key_content)\n",
    "\n",
    "print(\"File .cdsapirc berhasil dibuat/diperbarui!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55671330",
   "metadata": {},
   "source": [
    "## Fase 2: Akuisisi Data Massal (Mengunduh Data 5 Tahun)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17b49a",
   "metadata": {},
   "source": [
    "### Langkah 2.1: Tentukan Parameter Permintaan Anda\n",
    "\n",
    "Parameter tetap sama, tetapi kita akan menerapkannya dalam loop per-bulan.\n",
    "- Dataset: 'reanalysis-era5-single-levels'\n",
    "- Variabel: 2m_temperature, total_precipitation, sea_surface_temperature, significant_height_of_combined_wind_waves_and_swell\n",
    "- Area (Aceh): [6.0, 94.5, 5.0, 96.0]\n",
    "- Format: netcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1d2d96",
   "metadata": {},
   "source": [
    "### Langkah 2.2: Skrip Python untuk Pengambilan Data (Loop per Bulan)\n",
    "\n",
    "Ganti skrip lama Anda dengan yang ini. Ini adalah skrip yang diperbaiki yang mengunduh data satu bulan pada satu waktu untuk menghindari error \"Request is too large\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba8e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai download untuk tahun 2019...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bulan 2019:   0%|          | 0/12 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mengirimkan permintaan untuk 2019-01...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 01:20:10,947 INFO Request ID is 2b99ffa2-9812-4fe3-84cc-70f2e0b4d8e4\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is 2b99ffa2-9812-4fe3-84cc-70f2e0b4d8e4\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is 2b99ffa2-9812-4fe3-84cc-70f2e0b4d8e4\n",
      "2025-11-25 01:20:11,084 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:20:11,084 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:20:20,331 INFO status has been updated to running\n",
      "2025-11-25 01:20:20,331 INFO status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "2025-11-25 01:24:32,932 INFO status has been updated to successful\n",
      "2025-11-25 01:24:32,932 INFO status has been updated to successful\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "013acedbbfe8437cad38ff192eb2cb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "e4e837efa11fdac314baf7d90b671816.zip:   0%|          | 0.00/340k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bulan 2019:   8%|▊         | 1/12 [04:24<48:25, 264.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BERHASIL: aceh_data_2019_01.nc ---\n",
      "\n",
      "Mengirimkan permintaan untuk 2019-02...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 01:24:34,942 INFO Request ID is a9bf18d5-f783-42d9-a94d-70d955d8c467\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is a9bf18d5-f783-42d9-a94d-70d955d8c467\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is a9bf18d5-f783-42d9-a94d-70d955d8c467\n",
      "2025-11-25 01:24:35,284 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:24:35,284 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:24:44,612 INFO status has been updated to running\n",
      "2025-11-25 01:24:44,612 INFO status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "2025-11-25 01:28:57,411 INFO status has been updated to successful\n",
      "2025-11-25 01:28:57,411 INFO status has been updated to successful\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ff42a77667491da6e5a07e30316abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "59efd2d674997b47ae216675c61ac82b.zip:   0%|          | 0.00/322k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Bulan 2019:  17%|█▋        | 2/12 [08:48<44:03, 264.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- BERHASIL: aceh_data_2019_02.nc ---\n",
      "\n",
      "Mengirimkan permintaan untuk 2019-03...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-25 01:28:59,446 INFO Request ID is fb7d2f1e-3577-47d5-b0bd-c1cfe2c03657\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is fb7d2f1e-3577-47d5-b0bd-c1cfe2c03657\n",
      "INFO:ecmwf.datastores.legacy_client:Request ID is fb7d2f1e-3577-47d5-b0bd-c1cfe2c03657\n",
      "2025-11-25 01:28:59,795 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:28:59,795 INFO status has been updated to accepted\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to accepted\n",
      "2025-11-25 01:29:05,373 INFO status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "2025-11-25 01:29:05,373 INFO status has been updated to running\n",
      "INFO:ecmwf.datastores.legacy_client:status has been updated to running\n",
      "Bulan 2019:  17%|█▋        | 2/12 [15:38<1:18:13, 469.31s/it]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-63499417.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mretry_count\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             client.retrieve(\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0;34m'reanalysis-era5-single-levels'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 {\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ecmwf/datastores/legacy_client.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self, name, request, target)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0msubmitted\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatastores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRemote\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdatastores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_until_complete\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             submitted = self.client.submit_and_wait_on_results(\n\u001b[0m\u001b[1;32m    168\u001b[0m                 \u001b[0mcollection_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ecmwf/datastores/client.py\u001b[0m in \u001b[0;36msubmit_and_wait_on_results\u001b[0;34m(self, collection_id, request)\u001b[0m\n\u001b[1;32m    412\u001b[0m         \u001b[0mdatastores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \"\"\"\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_retrieve_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0munstar_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollection_id\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ecmwf/datastores/processing.py\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m         \u001b[0mdatastores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m         \"\"\"\n\u001b[0;32m--> 495\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ecmwf/datastores/processing.py\u001b[0m in \u001b[0;36m_make_results\u001b[0;34m(self, wait)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mResults\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_on_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_api_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ecmwf/datastores/processing.py\u001b[0m in \u001b[0;36m_wait_on_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"results not ready, waiting for {sleep} seconds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m             \u001b[0msleep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Script untuk tahun 2019\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2019'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7752e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script untuk tahun 2020\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2020'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ea64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script untuk tahun 2021\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2021'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8cdd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script untuk tahun 2022\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2022'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbac797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script untuk tahun 2023\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2023'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080f32ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script untuk tahun 2024\n",
    "import cdsapi\n",
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Buat folder data_iklim jika belum ada\n",
    "os.makedirs('data_iklim', exist_ok=True)\n",
    "\n",
    "client = cdsapi.Client()\n",
    "\n",
    "year = '2024'\n",
    "all_months = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12']\n",
    "all_days = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31']\n",
    "all_times = ['00:00', '01:00', '02:00', '03:00', '04:00', '05:00', '06:00', '07:00', '08:00', '09:00', '10:00', '11:00', '12:00', '13:00', '14:00', '15:00', '16:00', '17:00', '18:00', '19:00', '20:00', '21:00', '22:00', '23:00']\n",
    "\n",
    "successful_downloads = 0\n",
    "failed_downloads = 0\n",
    "\n",
    "print(f\"Memulai download untuk tahun {year}...\")\n",
    "\n",
    "for month in tqdm(all_months, desc=f\"Bulan {year}\"):\n",
    "    target_file = f'data_iklim/aceh_data_{year}_{month}.nc'\n",
    "    print(f\"\\nMengirimkan permintaan untuk {year}-{month}...\")\n",
    "    \n",
    "    max_retries = 3\n",
    "    retry_count = 0\n",
    "    \n",
    "    while retry_count < max_retries:\n",
    "        try:\n",
    "            client.retrieve(\n",
    "                'reanalysis-era5-single-levels',\n",
    "                {\n",
    "                    'product_type': 'reanalysis',\n",
    "                    'variable': [\n",
    "                        '2m_temperature', 'total_precipitation',\n",
    "                        'sea_surface_temperature', 'significant_height_of_combined_wind_waves_and_swell'\n",
    "                    ],\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'day': all_days,\n",
    "                    'time': all_times,\n",
    "                    'area': [6.0, 94.5, 5.0, 96.0],\n",
    "                    'format': 'netcdf',\n",
    "                },\n",
    "                target_file\n",
    "            )\n",
    "            print(f\"--- BERHASIL: {target_file} ---\")\n",
    "            successful_downloads += 1\n",
    "            break\n",
    "        except Exception as e:\n",
    "            retry_count += 1\n",
    "            print(f\"!!! GAGAL {retry_count}/{max_retries}: {e}\")\n",
    "            if retry_count < max_retries:\n",
    "                time.sleep(60 * retry_count)\n",
    "            else:\n",
    "                failed_downloads += 1\n",
    "\n",
    "print(f\"\\nSelesai untuk {year}: Berhasil {successful_downloads}, Gagal {failed_downloads}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e17341",
   "metadata": {},
   "source": [
    "### 2.3 Instruksi untuk Running Berkala\n",
    "\n",
    "Langkah 2.2 telah dipisahkan menjadi cell-cell terpisah untuk setiap tahun (2019-2024) agar memungkinkan download data secara bertahap dan berkala. Ini membantu menghindari overload pada CDS API dan memungkinkan Anda menjalankan download per tahun sesuai kebutuhan.\n",
    "\n",
    "**Cara menggunakan:**\n",
    "- Jalankan cell konfigurasi API terlebih dahulu (langkah 2.1).\n",
    "- Pilih tahun yang ingin Anda download, lalu jalankan cell Python yang sesuai untuk tahun tersebut.\n",
    "- Setiap cell akan mendownload data untuk 12 bulan dalam satu tahun, dengan retry logic dan progress tracking.\n",
    "- Jika download gagal untuk bulan tertentu, script akan mencoba ulang hingga 3 kali dengan delay yang meningkat.\n",
    "- Anda dapat menjalankan beberapa tahun secara berturut-turut atau menunggu antar tahun untuk menghindari batasan API.\n",
    "\n",
    "**Catatan penting:**\n",
    "- Pastikan token CDS API Anda valid dan memiliki kuota yang cukup.\n",
    "- Download untuk satu tahun penuh dapat memakan waktu beberapa jam tergantung pada antrian CDS.\n",
    "- Jika Anda hanya perlu data untuk bulan tertentu, edit script untuk menjalankan loop bulan yang diinginkan saja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcffd44",
   "metadata": {},
   "source": [
    "## Fase 3: Pemrosesan dan Transformasi Data\n",
    "\n",
    "Setelah data berhasil diunduh per tahun, langkah berikutnya adalah memproses dan mentransformasi data NetCDF menjadi format yang siap untuk database Android."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8055fa9c",
   "metadata": {},
   "source": [
    "### Langkah 3.1: Instal Pustaka Pemrosesan\n",
    "\n",
    "Jalankan di sel baru:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd053080",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xarray pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9294bf70",
   "metadata": {},
   "source": [
    "### Langkah 3.1: Muat dan Gabungkan Semua File .nc\n",
    "\n",
    "Kode berikut akan memuat semua file aceh_data_*.nc yang telah diunduh dari berbagai tahun, menggabungkannya menjadi satu set data besar, dan mengubahnya menjadi tabel Pandas (DataFrame). Pastikan Anda telah menjalankan download untuk tahun-tahun yang diinginkan sebelum menjalankan langkah ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11bf2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "\n",
    "# Muat dan gabungkan SEMUA file.nc yang telah diunduh\n",
    "print(\"Memuat dan menggabungkan file NetCDF...\")\n",
    "# Tanda bintang (*) di 'data_iklim/aceh_data_*.nc' akan menemukan semua 132+ file\n",
    "# (data_iklim/aceh_data_2014_01.nc, data_iklim/aceh_data_2014_02.nc, dst.)\n",
    "ds = xr.open_mfdataset('data_iklim/aceh_data_*.nc')\n",
    "\n",
    "# Konversi ke DataFrame Pandas\n",
    "print(\"Mengonversi ke DataFrame Pandas...\")\n",
    "df_hourly = ds.to_dataframe()\n",
    "\n",
    "# Data memiliki multi-indeks (lat, lon, time). Kita ratakan dan ambil rata-rata\n",
    "# dari titik grid (jika ada beberapa)\n",
    "df_hourly = df_hourly.reset_index()\n",
    "df_hourly = df_hourly.groupby('time').mean(numeric_only=True)\n",
    "\n",
    "# Ganti nama kolom agar lebih mudah dibaca\n",
    "df_hourly = df_hourly.rename(columns={\n",
    "    't2m': 'temp_celsius',\n",
    "    'tp': 'precipitation_mm',\n",
    "    'sst': 'sea_surface_temp_c',\n",
    "    'shww': 'wave_height_meters'\n",
    "})\n",
    "\n",
    "# Konversi suhu dari Kelvin ke Celsius (jika perlu, t2m & sst sudah dalam K)\n",
    "df_hourly['temp_celsius'] = df_hourly['temp_celsius'] - 273.15\n",
    "df_hourly['sea_surface_temp_c'] = df_hourly['sea_surface_temp_c'] - 273.15\n",
    "\n",
    "\n",
    "print(\"\\nData per jam berhasil dimuat:\")\n",
    "print(df_hourly.head())\n",
    "print(f\"\\nTotal baris data per jam: {len(df_hourly)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492850d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validasi data dasar\n",
    "print(\"Melakukan validasi data...\")\n",
    "print(f\"Jumlah baris sebelum filter: {len(df_hourly)}\")\n",
    "\n",
    "# Cek missing values\n",
    "missing_counts = df_hourly.isnull().sum()\n",
    "print(f\"Missing values per kolom:\\n{missing_counts}\")\n",
    "\n",
    "# Filter data yang valid (hapus baris dengan NaN jika ada)\n",
    "df_hourly = df_hourly.dropna()\n",
    "\n",
    "print(f\"Jumlah baris setelah filter: {len(df_hourly)}\")\n",
    "\n",
    "# Cek range nilai yang masuk akal\n",
    "print(\"Statistik deskriptif:\")\n",
    "print(df_hourly.describe())\n",
    "\n",
    "# Pastikan data dalam range fisik yang masuk akal\n",
    "# Suhu: -50°C sampai 60°C\n",
    "df_hourly = df_hourly[\n",
    "    (df_hourly['temp_celsius'] >= -50) & (df_hourly['temp_celsius'] <= 60) &\n",
    "    (df_hourly['sea_surface_temp_c'] >= -2) & (df_hourly['sea_surface_temp_c'] <= 35) &\n",
    "    (df_hourly['precipitation_mm'] >= 0) & (df_hourly['precipitation_mm'] <= 500) &  # mm/jam\n",
    "    (df_hourly['wave_height_meters'] >= 0) & (df_hourly['wave_height_meters'] <= 20)\n",
    "]\n",
    "\n",
    "print(f\"Jumlah baris setelah validasi range: {len(df_hourly)}\")\n",
    "print(\"Validasi selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce38aeb",
   "metadata": {},
   "source": [
    "### Langkah 3.3: Agregasi Data (Membuat Rata-rata)\n",
    "\n",
    "Data Anda sekarang per jam. Sesuai tujuan Anda, kita perlu membuat rata-rata Harian, Mingguan, dan Bulanan. Kita menggunakan fungsi resample() dari Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35887c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pastikan indeks adalah DatetimeIndex (ini penting untuk resample)\n",
    "df_hourly.index = pd.to_datetime(df_hourly.index)\n",
    "\n",
    "print(\"Membuat agregat Harian ('D')...\")\n",
    "df_daily = df_hourly.resample('D').mean()\n",
    "\n",
    "print(\"Membuat agregat Mingguan ('W')...\")\n",
    "df_weekly = df_hourly.resample('W').mean()\n",
    "\n",
    "print(\"Membuat agregat Bulanan ('M')...\")\n",
    "df_monthly = df_hourly.resample('M').mean()\n",
    "\n",
    "print(\"\\nContoh data rata-rata bulanan:\")\n",
    "print(df_monthly.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e11e0a",
   "metadata": {},
   "source": [
    "### Langkah 3.4: Membuat Tabel Klimatologi (Lookup)\n",
    "\n",
    "Ini adalah bagian terpenting untuk aplikasi Anda (\"melihat data cuaca rata2 pada hari/minggu/bulan\"). Kita akan membuat tabel lookup yang berisi rata-rata 10 tahun untuk setiap hari dalam setahun (1 Jan, 2 Jan, dst.) dan setiap bulan (Jan, Feb, dst.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef387c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Membuat tabel lookup klimatologi (rata-rata 10 tahun)...\")\n",
    "\n",
    "# 1. Rata-rata per HARI (1 s/d 366)\n",
    "# Mengelompokkan berdasarkan \"hari dalam setahun\"\n",
    "df_climatology_day_of_year = df_hourly.groupby(df_hourly.index.dayofyear).mean()\n",
    "df_climatology_day_of_year.index.name = 'day_of_year' # (1 = 1 Jan, 366 = 31 Des)\n",
    "\n",
    "# 2. Rata-rata per BULAN (1 s/d 12)\n",
    "# Mengelompokkan berdasarkan \"bulan\"\n",
    "df_climatology_month = df_hourly.groupby(df_hourly.index.month).mean()\n",
    "df_climatology_month.index.name = 'month' # (1 = Jan, 12 = Des)\n",
    "\n",
    "print(\"\\nContoh tabel Klimatologi per Bulan (rata-rata 10 tahun):\")\n",
    "print(df_climatology_month.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81359303",
   "metadata": {},
   "source": [
    "## Fase 4: Pembuatan Database SQLite Final\n",
    "\n",
    "Kita sekarang memiliki 5 tabel (DataFrame) yang siap disimpan ke dalam satu file database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9dbcd",
   "metadata": {},
   "source": [
    "### Langkah 4.1: Optimasi Indeks Tanggal (Opsional tapi Direkomendasikan)\n",
    "\n",
    "Untuk kueri yang lebih cepat di Android, sebaiknya simpan tanggal sebagai string yang dapat diindeks (YYYY-MM-DD) atau sebagai Unix timestamp (Integer) daripada objek Datetime lengkap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049166fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengonversi indeks Datetime menjadi string YYYY-MM-DD untuk kompatibilitas\n",
    "df_daily.index = df_daily.index.strftime('%Y-%m-%d')\n",
    "df_weekly.index = df_weekly.index.strftime('%Y-%m-%d')\n",
    "df_monthly.index = df_monthly.index.strftime('%Y-%m')\n",
    "\n",
    "# Menetapkan label indeks yang jelas untuk SQLite\n",
    "df_daily.index.name = 'date'\n",
    "df_weekly.index.name = 'week_start_date'\n",
    "df_monthly.index.name = 'month'\n",
    "\n",
    "print(\"Indeks telah dikonversi ke string untuk penyimpanan SQLite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff7b7b2",
   "metadata": {},
   "source": [
    "### Langkah 4.2: Menyimpan DataFrame ke SQLite\n",
    "\n",
    "Kita akan menggunakan pustaka sqlite3 bawaan Python dan metode .to_sql() dari Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17eda969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "db_filename = 'aceh_weather_data.sqlite'\n",
    "\n",
    "print(f\"Membuat koneksi ke database: {db_filename}\")\n",
    "con = sqlite3.connect(db_filename)\n",
    "\n",
    "# Menyimpan setiap DataFrame sebagai tabel terpisah\n",
    "print(\"Menyimpan tabel: daily_timeline...\")\n",
    "df_daily.to_sql('daily_timeline', con, if_exists='replace', index=True)\n",
    "\n",
    "print(\"Menyimpan tabel: weekly_timeline...\")\n",
    "df_weekly.to_sql('weekly_timeline', con, if_exists='replace', index=True)\n",
    "\n",
    "print(\"Menyimpan tabel: monthly_timeline...\")\n",
    "df_monthly.to_sql('monthly_timeline', con, if_exists='replace', index=True)\n",
    "\n",
    "print(\"Menyimpan tabel: climatology_by_day...\")\n",
    "df_climatology_day_of_year.to_sql('climatology_by_day', con, if_exists='replace', index=True)\n",
    "\n",
    "print(\"Menyimpan tabel: climatology_by_month...\")\n",
    "df_climatology_month.to_sql('climatology_by_month', con, if_exists='replace', index=True)\n",
    "\n",
    "# Menutup koneksi\n",
    "con.close()\n",
    "\n",
    "print(f\"\\n*** SELURUH PROSES SELESAI. ***\")\n",
    "print(f\"Database '{db_filename}' telah berhasil dibuat di lingkungan Colab.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dde513",
   "metadata": {},
   "source": [
    "### Langkah 4.3: Mengunduh File Database Final dari Colab\n",
    "\n",
    "Setelah sel di atas selesai, jalankan sel terakhir ini. Sel ini akan memicu unduhan browser untuk file aceh_weather_data.sqlite dari server Colab ke komputer lokal Anda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aab93f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "print(f\"Mempersiapkan unduhan untuk: {db_filename}\")\n",
    "files.download(db_filename)\n",
    "\n",
    "# Zip dan download folder data_iklim\n",
    "import shutil\n",
    "shutil.make_archive('data_iklim', 'zip', 'data_iklim')\n",
    "print(\"Mempersiapkan unduhan untuk: data_iklim.zip\")\n",
    "files.download('data_iklim.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
